{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hardware and software testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "import jax\n",
    "import jaxlib\n",
    "import flax\n",
    "\n",
    "import scanpy as sc\n",
    "import scvi\n",
    "import torch\n",
    "import scanorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print library versions\n",
    "print(\"JAX version:\", jax.__version__)\n",
    "print(\"JAXlib version:\", jaxlib.__version__)\n",
    "print(\"Flax version:\", flax.__version__)\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "\n",
    "print(\"PyTorch CUDA version:\", torch.version.cuda)\n",
    "print(\"scVI version:\", scvi.__version__)\n",
    "print(\"Scanpy version:\", sc.__version__)\n",
    "print(\"Scanorama version:\", scanorama.__version__)\n",
    "sc.logging.print_header()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU accelerated analysis\n",
    "\n",
    "The following code is designed to evaluate the presence of an Nvidia GPU with CUDA support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Pytorch has succssfully detected and loaded an Nvidia GPU with CUDA support\n",
    "if torch.cuda.is_available():\n",
    "\n",
    "    display(Markdown(\"## Facsimilab: Nvidia CUDA GPU Detected\"))\n",
    "    display(Markdown(f\"GPU Name: {torch.cuda.get_device_name(0)}\"))\n",
    "    display(Markdown(f\"GPU Available: {torch.cuda.is_available()}\"))\n",
    "\n",
    "    display(Markdown(\"### System Information\"))\n",
    "\n",
    "    display(Markdown(f\"- Python version: `{sys.version}` \\n - PyTorch version: `{torch.__version__}`\\n - CUDNN version: `{torch.backends.cudnn.version()}`\\n - Number CUDA Devices: `{torch.cuda.device_count()}`\"))\n",
    "\n",
    "    display(Markdown(\"### Devices\"))\n",
    "\n",
    "    display(Markdown(f\"- Available devices `{torch.cuda.device_count()}`\\n - Active CUDA device: `{torch.cuda.current_device()}`\"))\n",
    "\n",
    "    display(Markdown(\"Python starts numbering from '0'. Therefore, the `Active CUDA device` name/number is expected to be `0` above.\"))\n",
    "\n",
    "else:\n",
    "    display(Markdown(\"## No CUDA GPU Detected\"))\n",
    "    display(Markdown(\"This notebook will use the CPU instead of the GPU. Analysis time is expected to be _**significantly longer, but still possible.**_\"))\n",
    "\n",
    "    display(Markdown(f\"GPU Available: {torch.cuda.is_available()}\"))\n",
    "\n",
    "    display(Markdown(\"### System Information\"))\n",
    "\n",
    "    display(Markdown(f\"- Python version: `{sys.version}` \\n - PyTorch version: `{torch.__version__}`\\n - CUDNN version: `{torch.backends.cudnn.version()}`\\n - Number CUDA Devices: `{torch.cuda.device_count()}`\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
